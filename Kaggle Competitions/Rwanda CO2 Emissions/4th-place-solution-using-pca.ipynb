{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34f1861c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-08-07T19:42:34.088911Z",
     "iopub.status.busy": "2023-08-07T19:42:34.088565Z",
     "iopub.status.idle": "2023-08-07T19:42:39.303494Z",
     "shell.execute_reply": "2023-08-07T19:42:39.302244Z"
    },
    "papermill": {
     "duration": 5.225879,
     "end_time": "2023-08-07T19:42:39.306808",
     "exception": false,
     "start_time": "2023-08-07T19:42:34.080929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Callable, List\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.base import BaseEstimator, clone\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "TRAIN_CSV = '/kaggle/input/playground-series-s3e20/train.csv'\n",
    "TEST_CSV = '/kaggle/input/playground-series-s3e20/test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3835cc9",
   "metadata": {
    "papermill": {
     "duration": 0.005476,
     "end_time": "2023-08-07T19:42:39.318458",
     "exception": false,
     "start_time": "2023-08-07T19:42:39.312982",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Base pipeline classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30a71080",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T19:42:39.334736Z",
     "iopub.status.busy": "2023-08-07T19:42:39.332835Z",
     "iopub.status.idle": "2023-08-07T19:42:39.347158Z",
     "shell.execute_reply": "2023-08-07T19:42:39.345255Z"
    },
    "papermill": {
     "duration": 0.025765,
     "end_time": "2023-08-07T19:42:39.350087",
     "exception": false,
     "start_time": "2023-08-07T19:42:39.324322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class BaseAlgorithm(ABC):\n",
    "    @abstractmethod\n",
    "    def fit(self, train_df:pd.DataFrame): pass\n",
    "\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict(self, test_df:pd.DataFrame): pass\n",
    "\n",
    "    \n",
    "    def fit_predict(self, train_df:pd.DataFrame, test_df:pd.DataFrame):\n",
    "        self.fit(train_df)\n",
    "        return self.predict(test_df)\n",
    "\n",
    "    \n",
    "\n",
    "@dataclass\n",
    "class BasePipeline(ABC):\n",
    "    train_df: pd.DataFrame\n",
    "    test_df: pd.DataFrame\n",
    "    target: str\n",
    "        \n",
    "    metrics: Callable = None\n",
    "    algorithm: BaseAlgorithm = None\n",
    "    \n",
    "    def _clear_splits(self):\n",
    "        self.train_cv = []\n",
    "        self.val_cv = []\n",
    "        self.gt_cv = []\n",
    "\n",
    "\n",
    "    def _add_split(self, train_df, val_df, val_gt):\n",
    "        self.train_cv.append(train_df)\n",
    "        self.val_cv.append(val_df)\n",
    "        self.gt_cv.append(val_gt)        \n",
    "\n",
    "\n",
    "    @abstractmethod\n",
    "    def prepare_cv(self): pass            \n",
    "            \n",
    "        \n",
    "    def cv(self, use_train=False):\n",
    "        train_results = []\n",
    "        val_results = []\n",
    "        for (train_df, val_df, val_gt) in zip(self.train_cv, self.val_cv, self.gt_cv):\n",
    "            val_prediction = self.algorithm.fit_predict(train_df, val_df)\n",
    "            val_results.append(self.metrics(val_gt, val_prediction))\n",
    "\n",
    "            if use_train:\n",
    "                train_prediction = self.algorithm.predict(train_df.drop(self.target, axis=1))\n",
    "                train_results.append(self.metrics(train_df[self.target], train_prediction))\n",
    "        mean = np.mean(val_results)\n",
    "        std = np.std(val_results)\n",
    "        if use_train:\n",
    "            print(f'Train results={train_results}\\tVal results={val_results}\\tMean = {mean:.2f} ± {std:.2f}')\n",
    "        else:\n",
    "            print(f'Val results={val_results}\\tMean = {mean:.2f} ± {std:.2f}')\n",
    "\n",
    "        \n",
    "    def predict(self):\n",
    "        return self.algorithm.fit_predict(self.train_df, self.test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b93183",
   "metadata": {
    "papermill": {
     "duration": 0.005512,
     "end_time": "2023-08-07T19:42:39.364007",
     "exception": false,
     "start_time": "2023-08-07T19:42:39.358495",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d1cfa80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T19:42:39.379713Z",
     "iopub.status.busy": "2023-08-07T19:42:39.378667Z",
     "iopub.status.idle": "2023-08-07T19:42:39.392999Z",
     "shell.execute_reply": "2023-08-07T19:42:39.391306Z"
    },
    "papermill": {
     "duration": 0.026005,
     "end_time": "2023-08-07T19:42:39.395915",
     "exception": false,
     "start_time": "2023-08-07T19:42:39.369910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    proc_col = '__csv_n'\n",
    "    def __init__(self, csvs):\n",
    "        dfs = []\n",
    "        self.df_n = len(csvs)\n",
    "        for c, csv in enumerate(csvs):\n",
    "            df = pd.read_csv(csv)\n",
    "            df[self.proc_col] = c\n",
    "            dfs.append(df)\n",
    "        \n",
    "        self.df = pd.concat(dfs)\n",
    "        self.add_place_id()\n",
    "        self.add_date_column()\n",
    "\n",
    "\n",
    "    def get_dfs(self):\n",
    "        return [self.df[self.df[self.proc_col] == n].drop(self.proc_col, axis=1) for n in range(self.df_n)]\n",
    "\n",
    "\n",
    "    def add_place_id(self, preserve_place_str=False):\n",
    "        coordinates = [str(row[0]) + '_' + str(row[1]) for _, row in self.df[['latitude', 'longitude']].drop_duplicates().iterrows()]\n",
    "        coords = dict(zip(coordinates, range(len(coordinates))))\n",
    "\n",
    "        self.df['place'] = self.df.latitude.astype(str) + '_' + self.df.longitude.astype(str)\n",
    "        self.df['pid'] = self.df.place.map(coords)\n",
    "        self.coords = np.array([tuple(row) for _, row in self.df[['latitude', 'longitude']].drop_duplicates().iterrows()])\n",
    "        \n",
    "        if not preserve_place_str:\n",
    "            self.df.drop('place', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    def add_date_column(self):\n",
    "        self.df['date'] = self.df.year + self.df.week_no / 100\n",
    "        self.df['month'] = self.df[['year', 'week_no']].apply(lambda row: datetime.datetime.strptime(f'{row[\"year\"]}-{row[\"week_no\"]+1}-1', \"%Y-%W-%w\").month, axis=1)\n",
    "        self.df['is_covid'] = (self.df['year'] == 2020) & (self.df['month'] > 2) | (self.df['year'] == 2021) & (self.df['month'] == 1)\n",
    "        self.df['is_lockdown'] = (self.df['year'] == 2020) & ((self.df['month'].isin([3,4])))        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb03e075",
   "metadata": {
    "papermill": {
     "duration": 0.005777,
     "end_time": "2023-08-07T19:42:39.407148",
     "exception": false,
     "start_time": "2023-08-07T19:42:39.401371",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afde5bb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T19:42:39.420080Z",
     "iopub.status.busy": "2023-08-07T19:42:39.419710Z",
     "iopub.status.idle": "2023-08-07T19:42:39.430345Z",
     "shell.execute_reply": "2023-08-07T19:42:39.428907Z"
    },
    "papermill": {
     "duration": 0.02013,
     "end_time": "2023-08-07T19:42:39.433065",
     "exception": false,
     "start_time": "2023-08-07T19:42:39.412935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Pipeline(BasePipeline):\n",
    "    # This defines how CV is organized\n",
    "    # Particularly, we create 3-fold CV based on 3 available years\n",
    "    def prepare_cv(self):\n",
    "        self._clear_splits()\n",
    "        for year in range(2019, 2022):\n",
    "            train_df = self.train_df[(self.train_df.year != year)].copy()\n",
    "            val_df = self.train_df[self.train_df.year == year].copy()\n",
    "            val_gt = val_df[self.target]\n",
    "            val_df.drop(self.target, axis=1, inplace=True)\n",
    "            self._add_split(train_df, val_df, val_gt)\n",
    "            \n",
    "class Pipeline2021(BasePipeline):\n",
    "    # This defines how CV is organized\n",
    "    # Particularly, we create 3-fold CV based on 3 available years\n",
    "    def prepare_cv(self):\n",
    "        self._clear_splits()\n",
    "        for train_ys, val_ys in [((2019, ), (2020, )), ((2020, ), (2021, )), ((2019, ), (2020, 2021)), ((2019, 2020), (2021, )), ]:\n",
    "            train_df = self.train_df[self.train_df.year.isin(train_ys)].copy()\n",
    "            val_df = self.train_df[self.train_df.year.isin(val_ys)].copy()\n",
    "            val_gt = val_df[self.target]\n",
    "            val_df.drop(self.target, axis=1, inplace=True)\n",
    "            self._add_split(train_df, val_df, val_gt)          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a117a1",
   "metadata": {
    "papermill": {
     "duration": 0.005245,
     "end_time": "2023-08-07T19:42:39.443739",
     "exception": false,
     "start_time": "2023-08-07T19:42:39.438494",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PCA1 Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35700e7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T19:42:39.457064Z",
     "iopub.status.busy": "2023-08-07T19:42:39.456711Z",
     "iopub.status.idle": "2023-08-07T19:42:39.471652Z",
     "shell.execute_reply": "2023-08-07T19:42:39.470120Z"
    },
    "papermill": {
     "duration": 0.024528,
     "end_time": "2023-08-07T19:42:39.474237",
     "exception": false,
     "start_time": "2023-08-07T19:42:39.449709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    @dataclass\n",
    "    class PCAAlgorithm1(BaseAlgorithm):\n",
    "        pca_components: int = 6\n",
    "        normalize: bool = False\n",
    "\n",
    "        def fit(self, train_df:pd.DataFrame): \n",
    "            data = train_df.sort_values(['year', 'week_no'])[['pid', 'date', 'emission']].pivot(index='date', columns='pid', values='emission')\n",
    "\n",
    "            if self.normalize:\n",
    "                mean_values = train_df.groupby('pid').emission.mean().to_numpy()\n",
    "                data = data / mean_values\n",
    "                data = data.fillna(0)\n",
    "            else:\n",
    "                mean_values = 1\n",
    "\n",
    "            pca = PCA(n_components = self.pca_components, whiten = True)\n",
    "            data_t = pca.fit_transform(data.to_numpy())\n",
    "\n",
    "            data_pca = np.mean(data_t.reshape((-1, 53, self.pca_components)), axis=0)\n",
    "            self.pca_pred = pca.inverse_transform(data_pca)\n",
    "            self.pca_pred = np.multiply(self.pca_pred, mean_values)\n",
    "\n",
    "\n",
    "        def predict(self, test_df:pd.DataFrame):\n",
    "            return [self.pca_pred[int((row.date % 1)*100), row.pid] for _, row in test_df.iterrows()]\n",
    "\n",
    "\n",
    "\n",
    "    proc = Preprocessor([TRAIN_CSV, TEST_CSV])\n",
    "    train_df, test_df = proc.get_dfs()\n",
    "\n",
    "    pl = Pipeline2021(train_df = train_df, \n",
    "                  test_df = test_df, \n",
    "                  target = 'emission', \n",
    "                  metrics = lambda y_true, y_pred: np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "                  algorithm = PCAAlgorithm1(pca_components=6, normalize=False)\n",
    "                 )\n",
    "\n",
    "    pl.prepare_cv()\n",
    "    pl.cv()\n",
    "\n",
    "    submit_df = pd.read_csv('/kaggle/input/playground-series-s3e20/sample_submission.csv')\n",
    "    submit_df.emission = pl.predict()\n",
    "    submit_df.to_csv('submission_pca1.csv', index=False)\n",
    "\n",
    "    !head submission_pca1.csv\n",
    "    \n",
    "# Train results=[17.400447992446068, 13.860394893214197, 19.70961734612705]\tVal results=[23.762264618054928, 30.222470534371666, 16.496753769909112]\tMean = 23.49 ± 5.61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2933a672",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T19:42:39.486748Z",
     "iopub.status.busy": "2023-08-07T19:42:39.486147Z",
     "iopub.status.idle": "2023-08-07T19:42:39.494527Z",
     "shell.execute_reply": "2023-08-07T19:42:39.493151Z"
    },
    "papermill": {
     "duration": 0.017636,
     "end_time": "2023-08-07T19:42:39.497363",
     "exception": false,
     "start_time": "2023-08-07T19:42:39.479727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    pca_components = 6\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=pca_components)\n",
    "    fig.set_size_inches(30, 10)\n",
    "\n",
    "    data = train_df.sort_values(['year', 'week_no'])[['pid', 'date', 'emission']].pivot(index='date', columns='pid', values='emission')\n",
    "\n",
    "    pcas = (PCA(n_components=pca_components, whiten=True), PCA(n_components=pca_components, whiten=True))\n",
    "    data1 = pcas[0].fit_transform(data.to_numpy())\n",
    "\n",
    "    mean_values = train_df.groupby('pid').emission.mean()\n",
    "    data = data / mean_values\n",
    "    data = data.fillna(0)\n",
    "\n",
    "    data2 = pcas[1].fit_transform(data.to_numpy())\n",
    "\n",
    "    for m, pca in enumerate(pcas):\n",
    "        for n in range(pca.n_components_):\n",
    "            p = ax[m, n].tripcolor(proc.coords[:, 0], proc.coords[:, 1], pca.components_[n])\n",
    "            ax[m, n].set_title(f'PCA_{n} (Explained {pca.explained_variance_ratio_[n]:.3f})')\n",
    "            ax[m, n].plot(proc.coords[:, 0], proc.coords[:, 1], 'w.', markersize=1)\n",
    "            fig.colorbar(p, ax=ax[m, n])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a729d56",
   "metadata": {
    "papermill": {
     "duration": 0.005115,
     "end_time": "2023-08-07T19:42:39.507989",
     "exception": false,
     "start_time": "2023-08-07T19:42:39.502874",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PCA2 Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "220a492d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T19:42:39.520199Z",
     "iopub.status.busy": "2023-08-07T19:42:39.519839Z",
     "iopub.status.idle": "2023-08-07T19:42:44.325761Z",
     "shell.execute_reply": "2023-08-07T19:42:44.324116Z"
    },
    "papermill": {
     "duration": 4.815027,
     "end_time": "2023-08-07T19:42:44.328355",
     "exception": false,
     "start_time": "2023-08-07T19:42:39.513328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    @dataclass\n",
    "    class PCAAlgorithm2(BaseAlgorithm):\n",
    "        reg: BaseEstimator\n",
    "        x_pca_components: int = 2\n",
    "        y_pca_components: int = 5\n",
    "\n",
    "        whiten: bool = False\n",
    "        use_all_data: bool = True\n",
    "\n",
    "        def pca_reduction(self, df, column, pca_components):\n",
    "            data = df.sort_values('date')[['pid', 'date', column]].pivot(index='date', columns='pid', values=column).fillna(0).to_numpy()\n",
    "            pca = PCA(n_components = pca_components, whiten = self.whiten)\n",
    "            data_transformed = pca.fit_transform(data)\n",
    "            return pca, data_transformed\n",
    "\n",
    "\n",
    "        def fit(self, train_df:pd.DataFrame): \n",
    "            self.columns = [col for col in train_df.columns if (col not in ('ID_LAT_LON_YEAR_WEEK', 'week_no')) & ('_' in col) & ('angle' not in col)]\n",
    "\n",
    "            self.pca_emission, data_emission = self.pca_reduction(train_df, 'emission', self.y_pca_components)\n",
    "            self.mean_emission = np.tile(np.mean(data_emission.reshape((-1, 53, self.y_pca_components)), axis = 0), [10, 1])\n",
    "\n",
    "            self.pcas = {}\n",
    "            data = []\n",
    "            for column in self.columns:\n",
    "                self.pcas[column], data_transformed = self.pca_reduction(train_df, column, self.x_pca_components)\n",
    "                data.append(data_transformed)\n",
    "            data.append(self.mean_emission[:data[0].shape[0], :])\n",
    "            if not self.use_all_data:\n",
    "                data = [data[-1]]\n",
    "            data = np.concatenate(data, axis=1)\n",
    "\n",
    "            self.regs = []\n",
    "            for n in range(data_emission.shape[1]):\n",
    "                reg = clone(self.reg)\n",
    "                reg.fit(data, data_emission[:, n])\n",
    "                self.regs.append(reg)\n",
    "\n",
    "\n",
    "        def predict(self, test_df:pd.DataFrame):\n",
    "            data = []\n",
    "            for column in self.columns:\n",
    "                dt = test_df.sort_values('date')[['pid', 'date', column]].pivot(index='date', columns='pid', values=column).fillna(0).to_numpy()\n",
    "\n",
    "                data_transformed = self.pcas[column].transform(dt)\n",
    "                data.append(data_transformed)\n",
    "            data.append(self.mean_emission[:data[0].shape[0], :])\n",
    "            if not self.use_all_data:\n",
    "                data = [data[-1]]\n",
    "            data = np.concatenate(data, axis=1)\n",
    "\n",
    "            data_emission = [reg.predict(data) for reg in self.regs]\n",
    "            data_emission = np.stack(data_emission, axis=1)\n",
    "            self.pca_pred = self.pca_emission.inverse_transform(data_emission)\n",
    "\n",
    "            return [self.pca_pred[row.week_no, row.pid] for _, row in test_df.iterrows()]\n",
    "\n",
    "\n",
    "    proc = Preprocessor([TRAIN_CSV, TEST_CSV])\n",
    "    train_df, test_df = proc.get_dfs()\n",
    "\n",
    "    algorithm = PCAAlgorithm2(reg=Lasso(1e5))\n",
    "\n",
    "    pl = Pipeline2021(train_df = train_df, \n",
    "                  test_df = test_df, \n",
    "                  target = 'emission', \n",
    "                  metrics = lambda y_true, y_pred: np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "                  algorithm = algorithm\n",
    "                 )\n",
    "\n",
    "    pl.prepare_cv()\n",
    "    #pl.cv()\n",
    "\n",
    "    # If using only data = [data[-1]]\n",
    "    # Train results=[20.21349667978781, 15.938638748036908, 20.47409658664885]\tVal results=[22.01175795461681, 28.570374103625394, 22.457737596452105]\tMean = 24.35 ± 2.99\n",
    "\n",
    "    # If using all data\n",
    "    # Train results=[21.473538199760156, 16.822880214830896, 21.64011790074873]\tVal results=[26.296124289279522, 29.566012563872942, 24.838323036590005]\tMean = 26.90 ± 1.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5551e2b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T19:42:44.343144Z",
     "iopub.status.busy": "2023-08-07T19:42:44.342806Z",
     "iopub.status.idle": "2023-08-07T19:43:04.450939Z",
     "shell.execute_reply": "2023-08-07T19:43:04.448991Z"
    },
    "papermill": {
     "duration": 20.118466,
     "end_time": "2023-08-07T19:43:04.453628",
     "exception": false,
     "start_time": "2023-08-07T19:42:44.335162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val results=[30.50433525005058, 28.99586680133778, 26.29923444148491, 19.86816651090668]\tMean = 26.42 ± 4.07\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    reg = XGBRegressor(n_estimators = 300, max_depth = 4, learning_rate = 0.01, subsample = 0.5)\n",
    "    pl.algorithm = PCAAlgorithm2(reg=reg, y_pca_components=8, use_all_data=True)\n",
    "    pl.cv()\n",
    "\n",
    "# If using only data = [data[-1]] LB = 32.99\n",
    "# Train results=[14.772877589451626, 10.431708039446768, 15.029053555985346]\tVal results=[20.003894149566104, 26.78881632449643, 19.529596231359957]\tMean = 22.11 ± 3.32\n",
    "\n",
    "# If using all data LB = 30.79\n",
    "# Train results=[17.021493159113582, 12.275437078774036, 18.349682595468735]\tVal results=[20.377598555024935, 26.948277636370044, 20.293793823631393]\tMean = 22.54 ± 3.12\n",
    "# Add is_covid & is_lockdown LB = 29.72\n",
    "# Train results=[16.849774005566104, 12.276671286446696, 16.57368345876184]\tVal results=[17.91517733569031, 26.9496417264071, 19.86816651090668]\tMean = 21.58 ± 3.88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bfc04f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T19:43:04.468251Z",
     "iopub.status.busy": "2023-08-07T19:43:04.467913Z",
     "iopub.status.idle": "2023-08-07T19:43:13.052458Z",
     "shell.execute_reply": "2023-08-07T19:43:13.050630Z"
    },
    "papermill": {
     "duration": 8.593805,
     "end_time": "2023-08-07T19:43:13.054997",
     "exception": false,
     "start_time": "2023-08-07T19:43:04.461192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID_LAT_LON_YEAR_WEEK,emission\r\n",
      "ID_-0.510_29.290_2022_00,4.225600456500926\r\n",
      "ID_-0.510_29.290_2022_01,4.458608191920423\r\n",
      "ID_-0.510_29.290_2022_02,4.493135033800828\r\n",
      "ID_-0.510_29.290_2022_03,4.493326904312325\r\n",
      "ID_-0.510_29.290_2022_04,4.537351006058987\r\n",
      "ID_-0.510_29.290_2022_05,4.522386123175717\r\n",
      "ID_-0.510_29.290_2022_06,4.485195647433133\r\n",
      "ID_-0.510_29.290_2022_07,4.520021307765288\r\n",
      "ID_-0.510_29.290_2022_08,4.538194857277172\r\n",
      "ID_LAT_LON_YEAR_WEEK,emission\r\n",
      "ID_-0.510_29.290_2022_00,4.225600456500926\r\n",
      "ID_-0.510_29.290_2022_01,4.458608191920423\r\n",
      "ID_-0.510_29.290_2022_02,4.493135033800828\r\n",
      "ID_-0.510_29.290_2022_03,4.493326904312325\r\n",
      "ID_-0.510_29.290_2022_04,4.537351006058987\r\n",
      "ID_-0.510_29.290_2022_05,4.522386123175717\r\n",
      "ID_-0.510_29.290_2022_06,4.485195647433133\r\n",
      "ID_-0.510_29.290_2022_07,4.520021307765288\r\n",
      "ID_-0.510_29.290_2022_08,4.538194857277172\r\n",
      "ID_LAT_LON_YEAR_WEEK,emission\r\n",
      "ID_-0.510_29.290_2022_00,4.225600456500926\r\n",
      "ID_-0.510_29.290_2022_01,4.458608191920423\r\n",
      "ID_-0.510_29.290_2022_02,4.493135033800828\r\n",
      "ID_-0.510_29.290_2022_03,4.493326904312325\r\n",
      "ID_-0.510_29.290_2022_04,4.537351006058987\r\n",
      "ID_-0.510_29.290_2022_05,4.522386123175717\r\n",
      "ID_-0.510_29.290_2022_06,4.485195647433133\r\n",
      "ID_-0.510_29.290_2022_07,4.520021307765288\r\n",
      "ID_-0.510_29.290_2022_08,4.538194857277172\r\n",
      "ID_LAT_LON_YEAR_WEEK,emission\r\n",
      "ID_-0.510_29.290_2022_00,4.225600456500926\r\n",
      "ID_-0.510_29.290_2022_01,4.458608191920423\r\n",
      "ID_-0.510_29.290_2022_02,4.493135033800828\r\n",
      "ID_-0.510_29.290_2022_03,4.493326904312325\r\n",
      "ID_-0.510_29.290_2022_04,4.537351006058987\r\n",
      "ID_-0.510_29.290_2022_05,4.522386123175717\r\n",
      "ID_-0.510_29.290_2022_06,4.485195647433133\r\n",
      "ID_-0.510_29.290_2022_07,4.520021307765288\r\n",
      "ID_-0.510_29.290_2022_08,4.538194857277172\r\n",
      "ID_LAT_LON_YEAR_WEEK,emission\r\n",
      "ID_-0.510_29.290_2022_00,4.225600456500926\r\n",
      "ID_-0.510_29.290_2022_01,4.458608191920423\r\n",
      "ID_-0.510_29.290_2022_02,4.493135033800828\r\n",
      "ID_-0.510_29.290_2022_03,4.493326904312325\r\n",
      "ID_-0.510_29.290_2022_04,4.537351006058987\r\n",
      "ID_-0.510_29.290_2022_05,4.522386123175717\r\n",
      "ID_-0.510_29.290_2022_06,4.485195647433133\r\n",
      "ID_-0.510_29.290_2022_07,4.520021307765288\r\n",
      "ID_-0.510_29.290_2022_08,4.538194857277172\r\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    emission = np.array(pl.predict())\n",
    "    \n",
    "\n",
    "    for mult in [1, 1.05, 1.06, 1.07, 1.08]:\n",
    "        submit_df = pd.read_csv('/kaggle/input/playground-series-s3e20/sample_submission.csv')\n",
    "        submit_df.emission = emission * 1.07\n",
    "        submit_df.loc[test_df['longitude']==29.321, 'emission'] = mult * train_df.loc[(train_df['year']==2021) & (train_df['week_no']<=48) & (train_df['longitude'] == 29.321), 'emission'].values\n",
    "        out = f'submission_pca2_x1.07_29.321x{mult:.2f}.csv'\n",
    "        submit_df.to_csv(out, index=False)\n",
    "        !head {out}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66057d66",
   "metadata": {
    "papermill": {
     "duration": 0.005765,
     "end_time": "2023-08-07T19:43:13.066829",
     "exception": false,
     "start_time": "2023-08-07T19:43:13.061064",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PCA_SARIMA Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "412bd1ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T19:43:13.080799Z",
     "iopub.status.busy": "2023-08-07T19:43:13.080374Z",
     "iopub.status.idle": "2023-08-07T19:43:13.097970Z",
     "shell.execute_reply": "2023-08-07T19:43:13.096917Z"
    },
    "papermill": {
     "duration": 0.027594,
     "end_time": "2023-08-07T19:43:13.100448",
     "exception": false,
     "start_time": "2023-08-07T19:43:13.072854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    @dataclass\n",
    "    class PCA_SARIMA_Algorithm(BaseAlgorithm):\n",
    "        sarimax_parameters: List\n",
    "        x_pca_components: int = 2\n",
    "        y_pca_components: int = 5\n",
    "\n",
    "        whiten: bool = False\n",
    "        use_all_data: bool = True\n",
    "\n",
    "        def pca_reduction(self, df, column, pca_components):\n",
    "            data = df.sort_values('date')[['pid', 'date', column]].pivot(index='date', columns='pid', values=column).fillna(0).to_numpy()\n",
    "            pca = PCA(n_components = pca_components, whiten = self.whiten)\n",
    "            data_transformed = pca.fit_transform(data)\n",
    "            return pca, data_transformed\n",
    "\n",
    "\n",
    "        def fit(self, train_df:pd.DataFrame):\n",
    "            assert(self.y_pca_components <= len(self.sarimax_parameters))\n",
    "\n",
    "            self.columns = [col for col in train_df.columns if (col not in ('ID_LAT_LON_YEAR_WEEK', 'week_no')) & ('_' in col) & ('angle' not in col) & ('is' not in col)]\n",
    "\n",
    "            self.pca_emission, data_emission = self.pca_reduction(train_df, 'emission', self.y_pca_components)\n",
    "\n",
    "            self.models = []\n",
    "            for n in range(self.y_pca_components):\n",
    "                model = SARIMAX(endog=data_emission[:, n], **self.sarimax_parameters[n]).fit(disp=False)\n",
    "                self.models.append(model)        \n",
    "\n",
    "            \"\"\"self.mean_emission = np.tile(np.mean(data_emission.reshape((-1, 53, self.y_pca_components)), axis = 0), [10, 1])\n",
    "\n",
    "            self.pcas = {}\n",
    "            data = []\n",
    "            for column in self.columns:\n",
    "                self.pcas[column], data_transformed = self.pca_reduction(train_df, column, self.x_pca_components)\n",
    "                data.append(data_transformed)\n",
    "            data.append(self.mean_emission[:data[0].shape[0], :])\n",
    "            if not self.use_all_data:\n",
    "                data = [data[-1]]\n",
    "            data = np.concatenate(data, axis=1)\n",
    "\n",
    "            self.regs = []\n",
    "            for n in range(data_emission.shape[1]):\n",
    "                reg = clone(self.reg)\n",
    "                reg.fit(data, data_emission[:, n])\n",
    "                self.regs.append(reg)\"\"\"\n",
    "\n",
    "\n",
    "        def predict(self, test_df:pd.DataFrame):\n",
    "            data_emission = [model.forecast(len(test_df.date.unique())) for model in self.models]\n",
    "\n",
    "\n",
    "            \"\"\"return\n",
    "            data = []\n",
    "            for column in self.columns:\n",
    "                dt = test_df.sort_values('date')[['pid', 'date', column]].pivot(index='date', columns='pid', values=column).fillna(0).to_numpy()\n",
    "\n",
    "                data_transformed = self.pcas[column].transform(dt)\n",
    "                data.append(data_transformed)\n",
    "            data.append(self.mean_emission[:data[0].shape[0], :])\n",
    "            if not self.use_all_data:\n",
    "                data = [data[-1]]\n",
    "            data = np.concatenate(data, axis=1)\"\"\"\n",
    "\n",
    "            #data_emission = [reg.predict(data) for reg in self.regs]\n",
    "            data_emission = np.stack(data_emission, axis=1)\n",
    "\n",
    "            self.pca_pred = self.pca_emission.inverse_transform(data_emission)\n",
    "\n",
    "            return [self.pca_pred[row.week_no, row.pid] for _, row in test_df.iterrows()]\n",
    "\n",
    "\n",
    "    proc = Preprocessor([TRAIN_CSV, TEST_CSV])\n",
    "    train_df, test_df = proc.get_dfs()\n",
    "\n",
    "    sarimax_parameters = [\n",
    "        {'order': (0, 0, 0), 'seasonal_order': (0, 1, 3, 53)},\n",
    "        {'order': (1, 0, 2), 'seasonal_order': (1, 1, 0, 53)},\n",
    "        {'order': (1, 0, 1), 'seasonal_order': (1, 1, 0, 53)},\n",
    "        {'order': (2, 0, 3), 'seasonal_order': (1, 1, 0, 53)},\n",
    "        {'order': (1, 0, 2), 'seasonal_order': (1, 1, 0, 53)},\n",
    "        {'order': (2, 1, 0), 'seasonal_order': (1, 1, 0, 53)},\n",
    "    ]\n",
    "\n",
    "    algorithm = PCA_SARIMA_Algorithm(sarimax_parameters=sarimax_parameters)\n",
    "\n",
    "    pl = Pipeline2021(train_df = train_df, \n",
    "                  test_df = test_df, \n",
    "                  target = 'emission', \n",
    "                  metrics = lambda y_true, y_pred: np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "                  algorithm = algorithm\n",
    "                 )\n",
    "\n",
    "    pl.prepare_cv()\n",
    "    pl.cv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a79b5be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T19:43:13.116015Z",
     "iopub.status.busy": "2023-08-07T19:43:13.115226Z",
     "iopub.status.idle": "2023-08-07T19:43:13.121091Z",
     "shell.execute_reply": "2023-08-07T19:43:13.120209Z"
    },
    "papermill": {
     "duration": 0.016666,
     "end_time": "2023-08-07T19:43:13.123554",
     "exception": false,
     "start_time": "2023-08-07T19:43:13.106888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    submit_df = pd.read_csv('/kaggle/input/playground-series-s3e20/sample_submission.csv')\n",
    "    submit_df.emission = pl.predict()\n",
    "    submit_df.to_csv('submission_pca_sarima.csv', index=False)\n",
    "\n",
    "    !head submission_pca_sarima.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "572c7174",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T19:43:13.138713Z",
     "iopub.status.busy": "2023-08-07T19:43:13.138083Z",
     "iopub.status.idle": "2023-08-07T19:43:13.146244Z",
     "shell.execute_reply": "2023-08-07T19:43:13.144803Z"
    },
    "papermill": {
     "duration": 0.019016,
     "end_time": "2023-08-07T19:43:13.148880",
     "exception": false,
     "start_time": "2023-08-07T19:43:13.129864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    def pca_reduction(df, column, pca_components):\n",
    "        data = df.sort_values('date')[['pid', 'date', column]].pivot(index='date', columns='pid', values=column).fillna(0).to_numpy()\n",
    "        pca = PCA(n_components = pca_components, whiten = False)\n",
    "        data_transformed = pca.fit_transform(data)\n",
    "        return pca, data_transformed\n",
    "\n",
    "    def err(pred, gt):\n",
    "        return np.sqrt(np.sum((pred - gt)**2) / np.sum(gt**2))\n",
    "\n",
    "    _, de = pca_reduction(train_df, 'emission', 20)\n",
    "\n",
    "    for n in range(5):\n",
    "        pred1 = algorithm.models[n].forecast(53)\n",
    "        pred2 = de[:, n].reshape((3, -1))[:2].mean(axis=0)\n",
    "        gt = de[53*2:53*3, n]\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(de[:, n])\n",
    "        plt.plot(range(53*2, 53*3), pred1)\n",
    "\n",
    "        print('\\n\\n=> ', err(pred1, gt), err(pred2, gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07b18caa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T19:43:13.162792Z",
     "iopub.status.busy": "2023-08-07T19:43:13.162390Z",
     "iopub.status.idle": "2023-08-07T19:43:13.169403Z",
     "shell.execute_reply": "2023-08-07T19:43:13.168424Z"
    },
    "papermill": {
     "duration": 0.015905,
     "end_time": "2023-08-07T19:43:13.171141",
     "exception": false,
     "start_time": "2023-08-07T19:43:13.155236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    _, de = pca_reduction(train_df, 'emission', 20)\n",
    "\n",
    "    for n in [5]:\n",
    "        fig, ax = plt.subplots(ncols=2, nrows=2)\n",
    "        fig.set_size_inches(24,10)\n",
    "        for m in range(3):\n",
    "            ax[0, 0].plot(de[m*53:(m+1)*53, n], label=f'{2019+m}')\n",
    "        ax[0, 0].legend()\n",
    "        ax[0, 1].plot(de[:, n])\n",
    "\n",
    "        sm.graphics.tsa.plot_acf(de[:, n], lags=78, ax=ax[1, 0])\n",
    "        sm.graphics.tsa.plot_pacf(de[:, n], lags=78, ax=ax[1, 1])\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2fac6b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T19:43:13.184463Z",
     "iopub.status.busy": "2023-08-07T19:43:13.184053Z",
     "iopub.status.idle": "2023-08-07T19:43:13.192637Z",
     "shell.execute_reply": "2023-08-07T19:43:13.191569Z"
    },
    "papermill": {
     "duration": 0.018057,
     "end_time": "2023-08-07T19:43:13.195097",
     "exception": false,
     "start_time": "2023-08-07T19:43:13.177040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    proc = Preprocessor([TRAIN_CSV, TEST_CSV])\n",
    "    train_df, test_df = proc.get_dfs()\n",
    "    _, de = pca_reduction(train_df, 'emission', 20)\n",
    "    _, de2 = pca_reduction(train_df[train_df.year != 2021], 'emission', 6)\n",
    "\n",
    "    n = 5\n",
    "\n",
    "    sarimax_parameters[n] = {'order': (1, 0, 1), 'seasonal_order': (1, 1, 0, 53)}\n",
    "    model = SARIMAX(endog=de2[:2*53, n], **sarimax_parameters[n])\n",
    "    pred1 = model.fit(disp=False).forecast(53)\n",
    "    #pred1 = algorithm.models[0].forecast(53)\n",
    "    pred2 = de[:, n].reshape((3, -1))[:2].mean(axis=0)\n",
    "    gt = de[53*2:53*3, n]\n",
    "\n",
    "    plt.plot(de[:, n], 'b')\n",
    "    plt.plot(de2[:, n], 'r--')\n",
    "    plt.plot(range(53*2, 53*3), pred1, 'r', linewidth=2)\n",
    "\n",
    "    print('\\n\\n=> ', err(pred1, gt), err(pred2, gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd4e8513",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T19:43:13.209453Z",
     "iopub.status.busy": "2023-08-07T19:43:13.209089Z",
     "iopub.status.idle": "2023-08-07T19:43:13.216352Z",
     "shell.execute_reply": "2023-08-07T19:43:13.215474Z"
    },
    "papermill": {
     "duration": 0.016425,
     "end_time": "2023-08-07T19:43:13.218135",
     "exception": false,
     "start_time": "2023-08-07T19:43:13.201710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    proc = Preprocessor([TRAIN_CSV, TEST_CSV])\n",
    "    train_df, test_df = proc.get_dfs()\n",
    "    _, de = pca_reduction(train_df, 'emission', 20)\n",
    "    _, de2 = pca_reduction(train_df[train_df.year != 2021], 'emission', 6)\n",
    "\n",
    "    n = 0\n",
    "\n",
    "    model = SARIMAX(endog=de2[:2*53, n], **sarimax_parameters[n]).fit(disp=False)\n",
    "    pred1 = model.forecast(53)\n",
    "    #pred1 = algorithm.models[0].forecast(53)\n",
    "    pred2 = de[:, n].reshape((3, -1))[:2].mean(axis=0)\n",
    "    gt = de[53*2:53*3, n]\n",
    "\n",
    "    plt.plot(de[:, n], 'b')\n",
    "    plt.plot(de2[:, n], 'r--')\n",
    "    plt.plot(range(53*2, 53*3), pred1, 'r', linewidth=2)\n",
    "\n",
    "    print('\\n\\n=> ', err(pred1, gt), err(pred2, gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3ce30b",
   "metadata": {
    "papermill": {
     "duration": 0.005591,
     "end_time": "2023-08-07T19:43:13.229896",
     "exception": false,
     "start_time": "2023-08-07T19:43:13.224305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7180f3",
   "metadata": {
    "papermill": {
     "duration": 0.006447,
     "end_time": "2023-08-07T19:43:13.242253",
     "exception": false,
     "start_time": "2023-08-07T19:43:13.235806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05da6f1",
   "metadata": {
    "papermill": {
     "duration": 0.005663,
     "end_time": "2023-08-07T19:43:13.253850",
     "exception": false,
     "start_time": "2023-08-07T19:43:13.248187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 49.815372,
   "end_time": "2023-08-07T19:43:14.482673",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-07T19:42:24.667301",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
