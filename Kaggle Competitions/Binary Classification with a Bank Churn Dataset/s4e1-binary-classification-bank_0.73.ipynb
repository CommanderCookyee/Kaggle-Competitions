{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":65711,"databundleVersionId":7405009,"sourceType":"competition"}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-02T14:05:41.474174Z","iopub.execute_input":"2024-01-02T14:05:41.475268Z","iopub.status.idle":"2024-01-02T14:05:41.854108Z","shell.execute_reply.started":"2024-01-02T14:05:41.475235Z","shell.execute_reply":"2024-01-02T14:05:41.853134Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Data Exploration\n- What is credit score ?\n- Remove the name ","metadata":{}},{"cell_type":"code","source":"train_set = pd.read_csv('/kaggle/input/playground-series-s4e1/train.csv')\ntest_set  = pd.read_csv('/kaggle/input/playground-series-s4e1/test.csv')\ntrain_set = train_set[['id', 'CustomerId', 'CreditScore', 'Geography', 'Gender',\n       'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n       'IsActiveMember', 'EstimatedSalary', 'Exited']]\n","metadata":{"execution":{"iopub.status.busy":"2024-01-02T14:05:41.856109Z","iopub.execute_input":"2024-01-02T14:05:41.856667Z","iopub.status.idle":"2024-01-02T14:05:42.395283Z","shell.execute_reply.started":"2024-01-02T14:05:41.856640Z","shell.execute_reply":"2024-01-02T14:05:42.394108Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# One hot encoding and Standard Scaler\n- When to use standard scalar and when to use minmax?\n    - not normally bell shaped is minmax\n    - normally bell shape is standard scaler \n- One hot encode the Country and Gender ","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler","metadata":{"execution":{"iopub.status.busy":"2024-01-02T14:05:42.396756Z","iopub.execute_input":"2024-01-02T14:05:42.398326Z","iopub.status.idle":"2024-01-02T14:05:43.760702Z","shell.execute_reply.started":"2024-01-02T14:05:42.398281Z","shell.execute_reply":"2024-01-02T14:05:43.759581Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# One-Hot Encode 'Gender' and 'Geography' separately\nencoded_gender = pd.get_dummies(train_set['Gender'], prefix='Gender').astype(int)\nencoded_geography = pd.get_dummies(train_set['Geography'], prefix='Geography').astype(int)\n\n# Concatenate the encoded DataFrames with the original DataFrame\ntrain_set = pd.concat([train_set, encoded_gender, encoded_geography], axis=1)\n\n# Drop the original 'Gender' and 'Geography' columns\ntrain_set = train_set.drop(columns=['Gender', 'Geography'])\n\n# One-Hot Encode 'Gender' and 'Geography' separately\nencoded_gender = pd.get_dummies(test_set['Gender'], prefix='Gender').astype(int)\nencoded_geography = pd.get_dummies(test_set['Geography'], prefix='Geography').astype(int)\n\n# Concatenate the encoded DataFrames with the original DataFrame\ntest_set = pd.concat([test_set, encoded_gender, encoded_geography], axis=1)\n\n# Drop the original 'Gender' and 'Geography' columns\ntest_set = test_set.drop(columns=['Gender', 'Geography'])\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-02T14:05:43.763624Z","iopub.execute_input":"2024-01-02T14:05:43.764990Z","iopub.status.idle":"2024-01-02T14:05:43.854740Z","shell.execute_reply.started":"2024-01-02T14:05:43.764944Z","shell.execute_reply":"2024-01-02T14:05:43.851693Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\n# Features to scale\nfeatures_to_scale = ['CreditScore', 'Age', 'Balance', 'EstimatedSalary']\n\n# Create a copy of the DataFrame to avoid modifying the original data\nscaled_train_set = train_set.copy()\n\n# Initialize the StandardScaler\nscaler = StandardScaler()\n\n# Fit and transform the selected features\nscaled_features = scaler.fit_transform(train_set[features_to_scale])\n\n# Create a DataFrame with the scaled features\nscaled_features_df = pd.DataFrame(scaled_features, columns=features_to_scale)\n\n# Replace the original features with the scaled features in the copied DataFrame\nscaled_train_set[features_to_scale] = scaled_features_df\n\n# Create a copy of the DataFrame to avoid modifying the original data\nscaled_test_set = test_set.copy()\n\n# Fit and transform the selected features\nscaled_features = scaler.fit_transform(test_set[features_to_scale])\n\n# Create a DataFrame with the scaled features\nscaled_features_df = pd.DataFrame(scaled_features, columns=features_to_scale)\n\n# Replace the original features with the scaled features in the copied DataFrame\nscaled_test_set[features_to_scale] = scaled_features_df\n","metadata":{"execution":{"iopub.status.busy":"2024-01-02T14:05:43.856248Z","iopub.execute_input":"2024-01-02T14:05:43.857259Z","iopub.status.idle":"2024-01-02T14:05:43.917916Z","shell.execute_reply.started":"2024-01-02T14:05:43.857213Z","shell.execute_reply":"2024-01-02T14:05:43.916996Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Base Line Modeling XGB","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\n\n# Assuming 'scaled_train_set' is your DataFrame with the scaled features\n# If you haven't scaled the features yet, you can use 'train_set' instead of 'scaled_train_set'\n\n# Features and target variable\nX = scaled_train_set[['CreditScore', 'Age', 'Tenure', 'Balance','NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary','Gender_Female', 'Gender_Male', 'Geography_France','Geography_Germany', 'Geography_Spain']]\ny = scaled_train_set['Exited']  # Replace 'Target_Column' with the actual target column name\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nXtrain = X_train.copy()\nXtest = X_test.copy()\n\n# Initialize the XGBoost Classifier\nmodel = XGBClassifier()\n\n# Fit the model on the training data\nmodel.fit(X_train, y_train)\n\n# Make predictions on the testing data\ny_pred = model.predict(X_test)\n\n# Evaluate the accuracy of the model\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Accuracy: {accuracy:.2f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-01-02T14:05:43.919306Z","iopub.execute_input":"2024-01-02T14:05:43.919800Z","iopub.status.idle":"2024-01-02T14:05:46.754893Z","shell.execute_reply.started":"2024-01-02T14:05:43.919769Z","shell.execute_reply":"2024-01-02T14:05:46.754089Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Accuracy: 0.87\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ensemble stacking ","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import KFold\n# Going to use these 5 base models for the stacking\nfrom sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n                              GradientBoostingClassifier, ExtraTreesClassifier)\nfrom sklearn.svm import SVC\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-01-02T14:05:46.755907Z","iopub.execute_input":"2024-01-02T14:05:46.756360Z","iopub.status.idle":"2024-01-02T14:05:46.762233Z","shell.execute_reply.started":"2024-01-02T14:05:46.756333Z","shell.execute_reply":"2024-01-02T14:05:46.761059Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Some useful parameters which will come in handy later on\nntrain = X_train.shape[0]\nntest = X_test.shape[0]\nSEED = 0 # for reproducibility\nNFOLDS = 5\nkf = KFold(n_splits=NFOLDS, random_state=42, shuffle=True)\n\n\n# Class to extend the Sklearn classifier\nclass SklearnHelper(object):\n    def __init__(self, clf, seed=0, params=None):\n        params['random_state'] = seed\n        self.clf = clf(**params)\n\n    def train(self, x_train, y_train):\n        self.clf.fit(x_train, y_train)\n\n    def predict(self, x):\n        return self.clf.predict(x)\n    \n    def fit(self,x,y):\n        return self.clf.fit(x,y)\n    \n    def feature_importances(self,x,y):\n        print(self.clf.fit(x,y).feature_importances_)","metadata":{"execution":{"iopub.status.busy":"2024-01-02T14:05:46.763755Z","iopub.execute_input":"2024-01-02T14:05:46.764130Z","iopub.status.idle":"2024-01-02T14:05:46.777737Z","shell.execute_reply.started":"2024-01-02T14:05:46.764063Z","shell.execute_reply":"2024-01-02T14:05:46.776212Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def get_oof(clf, x_train, y_train, x_test):\n    oof_train = np.zeros((ntrain,))\n    oof_test = np.zeros((ntest,))\n    oof_test_skf = np.empty((NFOLDS, ntest))\n\n    for i, (train_index, test_index) in enumerate(kf):\n        x_tr = x_train[train_index]\n        y_tr = y_train[train_index]\n        x_te = x_train[test_index]\n\n        clf.train(x_tr, y_tr)\n\n        oof_train[test_index] = clf.predict(x_te)\n        oof_test_skf[i, :] = clf.predict(x_test)\n\n    oof_test[:] = oof_test_skf.mean(axis=0)\n    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)","metadata":{"execution":{"iopub.status.busy":"2024-01-02T14:05:46.778949Z","iopub.execute_input":"2024-01-02T14:05:46.779315Z","iopub.status.idle":"2024-01-02T14:05:46.792039Z","shell.execute_reply.started":"2024-01-02T14:05:46.779285Z","shell.execute_reply":"2024-01-02T14:05:46.790642Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Put in our parameters for said classifiers\n# Random Forest parameters\nrf_params = {\n    'n_jobs': -1,\n    'n_estimators': 500,\n     'warm_start': True, \n     #'max_features': 0.2,\n    'max_depth': 6,\n    'min_samples_leaf': 2,\n    'max_features' : 'sqrt',\n    'verbose': 0\n}\n\n# Extra Trees Parameters\net_params = {\n    'n_jobs': -1,\n    'n_estimators':500,\n    #'max_features': 0.5,\n    'max_depth': 8,\n    'min_samples_leaf': 2,\n    'verbose': 0\n}\n\n# AdaBoost parameters\nada_params = {\n    'n_estimators': 500,\n    'learning_rate' : 0.75\n}\n\n# Gradient Boosting parameters\ngb_params = {\n    'n_estimators': 500,\n     #'max_features': 0.2,\n    'max_depth': 5,\n    'min_samples_leaf': 2,\n    'verbose': 0\n}\n\n# Support Vector Classifier parameters \nsvc_params = {\n    'kernel' : 'linear',\n    'C' : 0.025\n    }","metadata":{"execution":{"iopub.status.busy":"2024-01-02T14:05:46.795514Z","iopub.execute_input":"2024-01-02T14:05:46.796631Z","iopub.status.idle":"2024-01-02T14:05:46.807867Z","shell.execute_reply.started":"2024-01-02T14:05:46.796583Z","shell.execute_reply":"2024-01-02T14:05:46.805982Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Create 5 objects that represent our 4 models\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=svc_params)","metadata":{"execution":{"iopub.status.busy":"2024-01-02T14:05:57.222547Z","iopub.execute_input":"2024-01-02T14:05:57.222923Z","iopub.status.idle":"2024-01-02T14:05:57.228589Z","shell.execute_reply.started":"2024-01-02T14:05:57.222897Z","shell.execute_reply":"2024-01-02T14:05:57.227454Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def get_oof(clf, x_train, y_train, x_test):\n    oof_train = np.zeros((ntrain,))\n    oof_test = np.zeros((ntest,))\n    oof_test_skf = np.empty((NFOLDS, ntest))\n\n    for i, (train_index, test_index) in enumerate(kf):\n        x_tr = x_train[train_index]\n        y_tr = y_train[train_index]\n        x_te = x_train[test_index]\n\n        clf.train(x_tr, y_tr)\n\n        oof_train[test_index] = clf.predict(x_te)\n        oof_test_skf[i, :] = clf.predict(x_test)\n\n    oof_test[:] = oof_test_skf.mean(axis=0)\n    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)","metadata":{"execution":{"iopub.status.busy":"2024-01-02T14:06:00.567090Z","iopub.execute_input":"2024-01-02T14:06:00.567480Z","iopub.status.idle":"2024-01-02T14:06:00.574989Z","shell.execute_reply.started":"2024-01-02T14:06:00.567450Z","shell.execute_reply":"2024-01-02T14:06:00.573404Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"X_train = X_train.values\nX_test = X_test.values\ny_train = y_train.ravel()","metadata":{"execution":{"iopub.status.busy":"2024-01-02T14:06:01.565768Z","iopub.execute_input":"2024-01-02T14:06:01.566299Z","iopub.status.idle":"2024-01-02T14:06:01.576709Z","shell.execute_reply.started":"2024-01-02T14:06:01.566246Z","shell.execute_reply":"2024-01-02T14:06:01.575360Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def get_oof(clf, x_train, y_train, x_test, kf):\n    ntrain = x_train.shape[0]\n    ntest = x_test.shape[0]\n    \n    oof_train = np.zeros((ntrain,))\n    oof_test = np.zeros((ntest,))\n    oof_test_skf = np.empty((NFOLDS, ntest))\n\n    for i, (train_index, test_index) in enumerate(kf.split(x_train)):\n        x_tr = x_train[train_index]\n        y_tr = y_train[train_index]\n        x_te = x_train[test_index]\n\n        clf.fit(x_tr, y_tr)\n\n        oof_train[test_index] = clf.predict(x_te)\n        oof_test_skf[i, :] = clf.predict(x_test)\n\n    oof_test[:] = oof_test_skf.mean(axis=0)\n    return oof_train, oof_test\n","metadata":{"execution":{"iopub.status.busy":"2024-01-02T14:06:13.652786Z","iopub.execute_input":"2024-01-02T14:06:13.653090Z","iopub.status.idle":"2024-01-02T14:06:13.660546Z","shell.execute_reply.started":"2024-01-02T14:06:13.653067Z","shell.execute_reply":"2024-01-02T14:06:13.659245Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"scaled_test_set = scaled_test_set[['CreditScore', 'Age', 'Tenure',\n       'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember',\n       'EstimatedSalary', 'Gender_Female', 'Gender_Male', 'Geography_France',\n       'Geography_Germany', 'Geography_Spain']]","metadata":{"execution":{"iopub.status.busy":"2024-01-02T14:10:29.456850Z","iopub.execute_input":"2024-01-02T14:10:29.457232Z","iopub.status.idle":"2024-01-02T14:10:29.468481Z","shell.execute_reply.started":"2024-01-02T14:10:29.457205Z","shell.execute_reply":"2024-01-02T14:10:29.466047Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"scaled_test_set = scaled_test_set.values ","metadata":{"execution":{"iopub.status.busy":"2024-01-02T14:10:49.151554Z","iopub.execute_input":"2024-01-02T14:10:49.151945Z","iopub.status.idle":"2024-01-02T14:10:49.161303Z","shell.execute_reply.started":"2024-01-02T14:10:49.151911Z","shell.execute_reply":"2024-01-02T14:10:49.160003Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Create our OOF train and test predictions. These base results will be used as new features\net_oof_train, et_oof_test = get_oof(et, X_train, y_train, scaled_test_set,kf) # Extra Trees\nrf_oof_train, rf_oof_test = get_oof(rf,X_train, y_train, scaled_test_set,kf) # Random Forest\nada_oof_train, ada_oof_test = get_oof(ada, X_train, y_train, scaled_test_set,kf) # AdaBoost \ngb_oof_train, gb_oof_test = get_oof(gb,X_train, y_train, scaled_test_set,kf) # Gradient Boost\nsvc_oof_train, svc_oof_test = get_oof(svc,X_train, y_train, scaled_test_set,kf) # Support Vector Classifier\n\nprint(\"Training is complete\")","metadata":{"execution":{"iopub.status.busy":"2024-01-02T14:15:52.147048Z","iopub.execute_input":"2024-01-02T14:15:52.147466Z","iopub.status.idle":"2024-01-02T14:56:57.507333Z","shell.execute_reply.started":"2024-01-02T14:15:52.147432Z","shell.execute_reply":"2024-01-02T14:56:57.506191Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Training is complete\n","output_type":"stream"}]},{"cell_type":"code","source":"et_oof_train = et_oof_train.reshape(-1, 1)\nrf_oof_train = rf_oof_train.reshape(-1, 1)\nada_oof_train = ada_oof_train.reshape(-1, 1)\ngb_oof_train =gb_oof_train.reshape(-1, 1)\nsvc_oof_train =svc_oof_train.reshape(-1, 1)\n\n\net_oof_test = et_oof_test.reshape(-1, 1)\nrf_oof_test = rf_oof_test.reshape(-1, 1)\nada_oof_test = ada_oof_test.reshape(-1, 1)\ngb_oof_test =gb_oof_test.reshape(-1, 1)\nsvc_oof_test =svc_oof_test.reshape(-1, 1)","metadata":{"execution":{"iopub.status.busy":"2024-01-02T15:17:16.115026Z","iopub.execute_input":"2024-01-02T15:17:16.115379Z","iopub.status.idle":"2024-01-02T15:17:16.121871Z","shell.execute_reply.started":"2024-01-02T15:17:16.115355Z","shell.execute_reply":"2024-01-02T15:17:16.120459Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"x_train = np.concatenate(( et_oof_train, rf_oof_train, ada_oof_train, gb_oof_train, svc_oof_train), axis=1)\nx_test = np.concatenate(( et_oof_test, rf_oof_test, ada_oof_test, gb_oof_test, svc_oof_test), axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-01-02T15:17:17.454519Z","iopub.execute_input":"2024-01-02T15:17:17.454908Z","iopub.status.idle":"2024-01-02T15:17:17.465075Z","shell.execute_reply.started":"2024-01-02T15:17:17.454874Z","shell.execute_reply":"2024-01-02T15:17:17.463629Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"gbm = XGBClassifier(\n    #learning_rate = 0.02,\n n_estimators= 2000,\n max_depth= 4,\n min_child_weight= 2,\n #gamma=1,\n gamma=0.9,                        \n subsample=0.8,\n colsample_bytree=0.8,\n objective= 'binary:logistic',\n nthread= -1,\n scale_pos_weight=1).fit(x_train, y_train)\npredictions = gbm.predict(x_test)","metadata":{"execution":{"iopub.status.busy":"2024-01-02T15:17:18.938617Z","iopub.execute_input":"2024-01-02T15:17:18.940951Z","iopub.status.idle":"2024-01-02T15:17:25.070093Z","shell.execute_reply.started":"2024-01-02T15:17:18.940916Z","shell.execute_reply":"2024-01-02T15:17:25.069396Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"submission = test_set.copy()\nsubmission['Exited'] = predictions\n\nsubmission = submission[['id','Exited']]\nsubmission.to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2024-01-02T15:31:00.812939Z","iopub.execute_input":"2024-01-02T15:31:00.814412Z","iopub.status.idle":"2024-01-02T15:31:00.976624Z","shell.execute_reply.started":"2024-01-02T15:31:00.814358Z","shell.execute_reply":"2024-01-02T15:31:00.975583Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2024-01-02T15:30:52.855474Z","iopub.execute_input":"2024-01-02T15:30:52.855840Z","iopub.status.idle":"2024-01-02T15:30:52.868054Z","shell.execute_reply.started":"2024-01-02T15:30:52.855810Z","shell.execute_reply":"2024-01-02T15:30:52.866704Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"            id  Exited\n0       165034       0\n1       165035       1\n2       165036       0\n3       165037       0\n4       165038       0\n...        ...     ...\n110018  275052       0\n110019  275053       0\n110020  275054       0\n110021  275055       0\n110022  275056       0\n\n[110023 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Exited</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>165034</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>165035</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>165036</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>165037</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>165038</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>110018</th>\n      <td>275052</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>110019</th>\n      <td>275053</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>110020</th>\n      <td>275054</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>110021</th>\n      <td>275055</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>110022</th>\n      <td>275056</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>110023 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}